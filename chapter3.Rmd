# Chapter 3 - Logistic regression

<!---
Exploring data and interpreting logistic regresion analysis
-->
```{r echo = FALSE, results='hide', message=FALSE}
library(dplyr)
library(GGally)
library(ggplot2)
```
This time we'll take a look at student alcohol consumption. First off (although I did secretly load some libraries above), let's get the data that I've wrangled into shape earlier:

```{r}
alc <- read.csv("./data/alc_data.csv")
glimpse(alc)
```

Alright, so we have 382 observations of 35 variables, including information on which school they attend, sex, age, urban/rural living etc. Most importantly for our purposes we have information on both workday and weekend alcohol consumption. This I have already averaged to a daily measure of consumption and then arbitrarily decided that if that consumption surpasses the integer 2, the students in question are _high_ consumers of alcohol. In the following examples we shall see the results of this excessive consumption.
This data has been created by joining two separate datasets, one gathered at a math course, the other a Portugese language course. The numeric values have been averaged and rounded while for the non-numeric variables the value from the Math dataset is used. So for example the G1-G3 variables represent rounded averages of students' Math and Portugese school grades.

Now let's get analytical.I've been instructed to _study the relationships between high/low alcohol consumption and some other variables_. So that's what I'll do. There are many variables that have the potential to explain student alcohol consumption and I have to choose 4 of them. I'll pick the obvious ones first: failures, or the number of past class failures (would drive any sane person to the bottle) and sex (guys drink more - duh!). Oh, and age - that has got to be relevant - the older students drink more. Now, my fourth pick might be less obvious though it shouldn't. Internet access at home - if you don't have that, what else you gonna do? Right. So, my variables of choice, in hypothesized order of (absolute) relevance to alcohol consumption:

* sex
* age
* internet
* failures


Here's a quick glance at those variables:
```{r}
summary(alc$sex)
summary(alc$age)
summary(alc$internet)
summary(alc$failures)
```
Ok, so this doesn't tell me so much just yet. About 50-50 female/male. Mean age just under 17 years, span 15-22. Most have a working internet connection at home, and the summary of the failures variable looks really weird.

Let's look at some plots to get a feel for these variables. Let's start with a simple bar plot colored by sex:

```{r}
g1 <- ggplot(data=alc, aes(x = high_use, fill = sex))
g1 + geom_bar()
```

So easy guess, the ratio of non-high to high consumers looks way higher for females. That should be a significant predictor of high alcohol consumption.Now let's look at age:

```{r}
g2 <- ggplot(data=alc, aes(x = high_use, y = age, col = sex))
g2 + geom_jitter()
```

When looking at the relationship between age and high alcohol consumption through a jitter-plot, it does seem pretty random. Based on this I don't think age is going to be a significant predictor of alcohol consumption.

Next up, internet. For this, a simple cross-tabulation will give us some indication of the relationship between internet access and high alcohol consumption:
```{r}
table(alc$high_use, alc$internet)
```
Seems like the ratios are pretty comparable, but we'll check it out with glm soon enough.

Last up, school failures:
```{r}
table(alc$high_use, alc$failures)
```
To start with, this variable is very heavily zero-inflated, so we'll see what we can do with it. It does seem however that the ratio of school failures vs none is rather inflated for students with high alcohol use.

Now I'll just chuck these in a logistic regrerssion model and we'll see what comes out:
```{r}
my_glmodel <- glm(high_use ~ sex + age + internet + failures, data = alc, family="binomial")
summary(my_glmodel)

```
  
We'll now take a closer look at each of these variables by interpreting them as odds ratios and looking at the confidence intervals:

```{r}
OR <- coef(my_glmodel) %>% exp
CI <- confint(my_glmodel) %>% exp
cbind(OR, CI)
```
A look at the confidence intervals shows us that in accordance with our hypotheses (those informed by graphs/cross-tabs):

  * Males are more likely to be high users (CI does not contain 1)
  * Age is not a statistically significant predictor of alcohol use (CI contains 1)
  * Neither is internet access (CI contains 1)
  * School failures seems to predict alcohol use (CI does not contain 1)



I'll do a quick rerun with a simplified model:
```{r}
my_glmodel2 <- glm(high_use ~ sex + failures, data = alc, family = "binomial")
summary(my_glmodel2)
coef(my_glmodel2)
```

Ok, so in this simplified model Male sex and number of failures predict alcohol usage. The coefficients are presented separately above for clarity.

Next I'll use the model to predict probabilties of high use and tabulate these.

```{r}
probabilities <- predict(my_glmodel2, type = "response")
alc <- mutate(alc, probability = probabilities)
alc <- mutate(alc, prediction = probability > 0.5)
table(high_use = alc$high_use, prediction = alc$prediction)
```

Ok, so this so called _confusion matrix_ tells me that my model gives 261 true negatives, 11 true positives, 103 false negatives and 7 false positives. I have a hard time telling if that's good or bad, so I'll plot it to see if it makes me more confident.

```{r}
g3 <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))
g3 + geom_point()
```

To be honest that didn't help me very much. I'll calculate the mean prediction error to see if that makes sense:
```{r}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}
loss_func(class=alc$high_use, alc$probability)
```
So this figure would indicate that a mean of 29% of the predictions of this model are wrong, right? So that means a mean of 71% is correct. Now, if we were to assign these students to high/non-high alcohol usage with no data we'd probably get about 50% right, so we're a bit better off using the model.

Now for some bonus points I'll do a bit of cross-validating (I'll be needing those points I guess...).

```{r}
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = my_glmodel2, K = 10)
cv$delta[1]
```
So this model, using 10-fold cross-validation, does not outperform the DataCamp model (0.29 vs DC's 0.26). If I have time before Friday, I'll go about looking for some predictors to outperform the DC model. If you are assessing this and this is the last line you read, I was not able to find time for that...